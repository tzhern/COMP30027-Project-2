{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hern/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.21.3 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from load_data import *\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    arr_steps = df['steps'].copy().to_numpy()\n",
    "    arr_ingr = df['ingredients'].copy().to_numpy()\n",
    "    for i in range(len(arr_steps)):\n",
    "        arr_steps[i] = str(arr_steps[i]).replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").replace(\"'\", \"\")\n",
    "        arr_ingr[i] = str(arr_ingr[i]).replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").replace(\"'\", \"\")\n",
    "    \n",
    "    X = arr_steps + arr_ingr\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_steps = df_train['steps'].copy().to_numpy()\n",
    "arr_ingr = df_train['ingredients'].copy().to_numpy()\n",
    "for i in range(len(arr_steps)):\n",
    "    arr_steps[i] = str(arr_steps[i]).replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").replace(\"'\", \"\")\n",
    "    arr_ingr[i] = str(arr_ingr[i]).replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").replace(\"'\", \"\")\n",
    "steps_srs = pd.Series(arr_steps)\n",
    "\n",
    "steps = steps_srs.str.cat(sep=' ')\n",
    "tokens = word_tokenize(steps)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokens = list(set(tokens))  # remove duplicates\n",
    "tokens = [w for w in tokens if not w in stop_words] # remove stop words\n",
    "# stemming\n",
    "ps = PorterStemmer()\n",
    "for i in range(len(tokens)):\n",
    "    tokens[i] = ps.stem(tokens[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "X = preprocess(df_train)\n",
    "y = df_train['duration_label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7955\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "penalties = ['l1', 'l2', 'elasticnet', 'none']\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "lg = LogisticRegression(random_state=0, max_iter=1000, solver='liblinear', penalty='l1', C=1.0)\n",
    "lg.fit(X_train, y_train)\n",
    "print(lg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocess(df_train)\n",
    "X_test = preprocess(df_test)\n",
    "y_train = df_train['duration_label']\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "lg = LogisticRegression(random_state=0, max_iter=1000, solver='liblinear', penalty='l1', C=1.0)\n",
    "lg.fit(X_train, y_train)\n",
    "predicts = lg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.array(range(len(predicts))) + 1\n",
    "output = pd.DataFrame({'id': ids, 'duration_label': predicts})\n",
    "output.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.791344 using {'C': 1.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.762906 (0.005463) with: {'C': 100, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.761156 (0.001928) with: {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.770250 (0.003837) with: {'C': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.763437 (0.005097) with: {'C': 100, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.764406 (0.005287) with: {'C': 100, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 100, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "0.000000 (0.000000) with: {'C': 100, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.747844 (0.005790) with: {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 100, 'penalty': 'l1', 'solver': 'sag'}\n",
      "0.760531 (0.005051) with: {'C': 100, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 100, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "0.000000 (0.000000) with: {'C': 100, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 100, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 100, 'penalty': 'elasticnet', 'solver': 'sag'}\n",
      "0.000000 (0.000000) with: {'C': 100, 'penalty': 'elasticnet', 'solver': 'saga'}\n",
      "0.781625 (0.004623) with: {'C': 10, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.781406 (0.004916) with: {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.786937 (0.004773) with: {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.781656 (0.004653) with: {'C': 10, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.781719 (0.004491) with: {'C': 10, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 10, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "0.000000 (0.000000) with: {'C': 10, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.776438 (0.003232) with: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 10, 'penalty': 'l1', 'solver': 'sag'}\n",
      "0.776594 (0.004009) with: {'C': 10, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 10, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "0.000000 (0.000000) with: {'C': 10, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 10, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 10, 'penalty': 'elasticnet', 'solver': 'sag'}\n",
      "0.000000 (0.000000) with: {'C': 10, 'penalty': 'elasticnet', 'solver': 'saga'}\n",
      "0.787906 (0.005344) with: {'C': 1.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.787875 (0.005168) with: {'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.787406 (0.004736) with: {'C': 1.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.787875 (0.005372) with: {'C': 1.0, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.787906 (0.005152) with: {'C': 1.0, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 1.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "0.000000 (0.000000) with: {'C': 1.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.791344 (0.003809) with: {'C': 1.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 1.0, 'penalty': 'l1', 'solver': 'sag'}\n",
      "0.790063 (0.003590) with: {'C': 1.0, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "0.000000 (0.000000) with: {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'sag'}\n",
      "0.000000 (0.000000) with: {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'saga'}\n",
      "0.766906 (0.005811) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.766906 (0.005811) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.756844 (0.004524) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.766906 (0.005811) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.766813 (0.005751) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.762281 (0.004525) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'sag'}\n",
      "0.763750 (0.003729) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'sag'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'saga'}\n",
      "0.718781 (0.003690) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.718781 (0.003641) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.705500 (0.002177) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.718781 (0.003690) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.718719 (0.003617) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 0.01, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "0.000000 (0.000000) with: {'C': 0.01, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.625594 (0.002526) with: {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 0.01, 'penalty': 'l1', 'solver': 'sag'}\n",
      "0.653312 (0.002299) with: {'C': 0.01, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "0.000000 (0.000000) with: {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'sag'}\n",
      "0.000000 (0.000000) with: {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# define models and parameters\n",
    "model = LogisticRegression()\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear', \"sag\", \"saga\"]\n",
    "penalty = ['l2', 'l1', 'elasticnet']\n",
    "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
    "# define grid search\n",
    "grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.767375"
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=0, max_leaf_nodes=100)\n",
    "dt.fit(X_train, y_train)\n",
    "dt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.779"
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = 200, random_state = 42)\n",
    "rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python388jvsc74a57bd0dce69896fdb445434427c12e791455610f9ef8e6bb07ea975426634cd43b3db3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}