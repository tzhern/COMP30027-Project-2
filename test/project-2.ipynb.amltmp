{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import joblib\n",
        "import warnings\n",
        "\n",
        "# seaborn\n",
        "import seaborn as sns\n",
        "\n",
        "# Sk learn model\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# load data\n",
        "from preprocess import *\n",
        "from utils import *"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/anaconda/envs/azureml_py38/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1620059809458
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# zero 0\n",
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "dummy_clf = DummyClassifier(strategy=\"prior\")\n",
        "dummy_clf_cv_results = cross_validate(dummy_clf, X, y, cv=10)\n",
        "dummy_clf_cv_results"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "X = arr_steps_vec_train\n",
        "y = df_train['duration_label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "\n",
        "lg = LogisticRegression(random_state=0, max_iter=1000)\n",
        "lg.fit(X_train, y_train)\n",
        "lg.score(X_test,y_test)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "0.7805"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1620059222171
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "(10000, 17967)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1620061698425
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lg = LogisticRegression(random_state=0, max_iter=1000)\n",
        "X_train = arr_steps_vec_train\n",
        "X_test = arr_steps_vec_test\n",
        "y_train = df_train['duration_label']\n",
        "lg.fit(X_train, y_train)\n",
        "predicts = lg.predict(X_test)\n",
        "ids = np.array(range(len(predicts))) + 1\n",
        "output = pd.DataFrame({'id': ids, 'duration_label': predicts})\n",
        "output.to_csv('outout_lg.csv', index=False)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1620060310216
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "y = df_train['duration_label']\n",
        "X = arr_steps_vec_train\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train, y_train)\n",
        "gnb.score(X_test, y_test)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "0.284375"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# decision tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dt = DecisionTreeClassifier(random_state=0, max_leaf_nodes=11)\n",
        "dt.fit(X_train, y_train)\n",
        "dt.score(X_test, y_test)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#multinomial nb\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "X = arr_steps_vec_train\n",
        "y = df_train['duration_label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "mnb = MultinomialNB(alpha=0.1)\n",
        "mnb.fit(X, y)\n",
        "mnb.score(X_test, y_test)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "0.761375"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "mnb = MultinomialNB()\n",
        "X_train = arr_steps_vec_train\n",
        "X_test = arr_steps_vec_test\n",
        "y_train = df_train['duration_label']\n",
        "mnb.fit(X_train, y_train)\n",
        "predicts = mnb.predict(X_test)"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# random forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier(n_estimators = 100, random_state = 42)\n",
        "cv_results = cross_validate(rf, X, y, cv=10)\n",
        "cv_results"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab_steps_dict_train.keys())"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 20,
          "data": {
            "text/plain": "17967"
          },
          "metadata": {}
        }
      ],
      "execution_count": 20,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# real test\n",
        "# preprocessing\n",
        "arr_x_train = df_train['ingredients'].to_numpy()\n",
        "arr_x_test = df_test['ingredients'].to_numpy()\n",
        "for i in range(len(arr_x_train)):\n",
        "    arr_x_train[i] = str(arr_x_train[i]).replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").replace(\"'\", \"\").split(\" \")\n",
        "for i in range(len(arr_x_test)):\n",
        "    arr_x_test[i] = str(arr_x_test[i]).replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").replace(\"'\", \"\").split(\" \")\n",
        "\n",
        "\n",
        "ingrs = list(vocab_ingr_dict_train.keys())\n",
        "mlb = MultiLabelBinarizer(classes = ingrs)\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "    X_train = mlb.fit_transform(arr_x_train)\n",
        "    X_test = mlb.fit_transform(arr_x_test)\n",
        "y_train = df_train['duration_label']"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 64-bit ('base': conda)",
      "name": "python385jvsc74a57bd0dce69896fdb445434427c12e791455610f9ef8e6bb07ea975426634cd43b3db3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "metadata": {
      "interpreter": {
        "hash": "dce69896fdb445434427c12e791455610f9ef8e6bb07ea975426634cd43b3db3"
      }
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}